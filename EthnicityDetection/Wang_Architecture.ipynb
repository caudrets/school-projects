{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Ethnicity Detection 2",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIfQY_8wnkRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##################################\n",
        "# Author: Christopher Audretsch\n",
        "# Date: April 27, 2020\n",
        "# Class: Image Processing, Adeel Bhutta\n",
        "# This is the generic image classification network, based on Wang et al's paper.\n",
        "##################################\n",
        "#Import Libraries\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from os import listdir\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EBJsk_ozjns",
        "colab_type": "code",
        "outputId": "60e7017b-5de5-4341-93e7-143d4af3f1f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3OCL1uPnkRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args={}\n",
        "kwargs={}\n",
        "args['batch_size']=1024\n",
        "args['test_batch_size']=1024\n",
        "args['epochs']=100  #The number of Epochs is the number of times you go through the full dataset. \n",
        "args['lr']=0.003 #Learning rate is how fast it will decend. \n",
        "args['momentum']=0.5 #SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n",
        "\n",
        "args['seed']=1 #random seed\n",
        "args['log_interval']=10\n",
        "args['cuda']=True\n",
        "\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/UTKFace\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8CRKzEls92E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EthnicityDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform = None, train = True, post = False):\n",
        "        # root_dir (string): Directory with all the images.\n",
        "        # transform: \n",
        "        random.seed(42)\n",
        "        self.root_dir = root_dir\n",
        "        self.image_paths = listdir(root_dir)\n",
        "        random.shuffle(self.image_paths)\n",
        "        if post:\n",
        "          self.image_paths = self.image_paths[12000:]\n",
        "        elif train:\n",
        "          self.image_paths = self.image_paths[:10000]\n",
        "        else:\n",
        "          self.image_paths = self.image_paths[10000:12000]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.root_dir + '/' + self.image_paths[idx])\n",
        "        # The labels of each face image is embedded in the file name, formated like [age]_[gender]_[race]_[date&time].jpg\n",
        "        # race is an integer from 0 to 4, denoting White, Black, Asian, Indian, and Others\n",
        "        race = (self.image_paths[idx].split('_')[2])\n",
        "        if race != '0' and race != '1' and race != '2' and race != '3' and race != '4':\n",
        "          race = '4'\n",
        "        race = int(race)\n",
        "        if self.transform:\n",
        "          image = self.transform(image)\n",
        "        return image, race"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z-GDuFhz_tP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_train = EthnicityDataset(path,transform = transforms.Compose([\n",
        "                       transforms.Grayscale(),\n",
        "                       transforms.Resize(64),\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((.497,), (.226,))\n",
        "                   ]))\n",
        "ds_test = EthnicityDataset(path, train = False, transform = transforms.Compose([\n",
        "                       transforms.Grayscale(),\n",
        "                       transforms.Resize(64),\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((.497,), (.226,))\n",
        "                   ]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqptffnC0lBL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the data\n",
        "train_loader = torch.utils.data.DataLoader(ds_train, batch_size=args['batch_size'], num_workers = 4, pin_memory = True, shuffle=True, **kwargs)\n",
        "#test_loader = torch.utils.data.DataLoader(ds_train2, batch_size=args['batch_size'], num_workers = 4, pin_memory = True, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(ds_test,batch_size=args['test_batch_size'], num_workers = 4, pin_memory = True, shuffle=True, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHdBmsn_nkRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    #This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5,padding=2,stride=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5,padding=2,stride=1)\n",
        "        self.conv3 = nn.Conv2d(32,64, kernel_size=5,padding=2,stride=1)\n",
        "        self.fc1 = nn.Linear(3136, 128)\n",
        "        self.fc2 = nn.Linear(128, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3,stride=2))\n",
        "        x = F.relu(F.avg_pool2d(self.conv2(x), kernel_size=3,stride=2))\n",
        "        x = F.relu(F.avg_pool2d(self.conv3(x), kernel_size=3,stride=2))\n",
        "        #Fully Connected Layer/Activation\n",
        "        x = x.view(-1, 3136)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7coWrNlVnkRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = []\n",
        "tests = []\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    #print('before for loop')\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if args['cuda']:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        #Variables in Pytorch are differenciable. \n",
        "        data, target = Variable(data), Variable(target)\n",
        "        #This will zero out the gradients for this batch. \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
        "        loss = F.nll_loss(output, target)\n",
        "        #dloss/dx for every Variable \n",
        "        loss.backward()\n",
        "        #to do a one-step update on our parameter.\n",
        "        optimizer.step()\n",
        "        #Print out the loss periodically. \n",
        "        if batch_idx % args['log_interval'] == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "    losses.append(loss.item())\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        if args['cuda']:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        x = pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "        correct += x\n",
        "    tests.append(int(correct) / len(test_loader.dataset))\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zPWNqVunkRy",
        "colab_type": "code",
        "outputId": "2776be90-a25d-48e3-bc98-9343ef35c316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#model = Net()\n",
        "if args['cuda']:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=args['momentum'])\n",
        "\n",
        "#for epoch in range(1, args['epochs'] + 1):\n",
        "for epoch in range(1, 50):\n",
        "    train(epoch)\n",
        "    test()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/10000 (0%)]\tLoss: 0.167846\n",
            "Train Epoch: 1 [2560/10000 (25%)]\tLoss: 0.196985\n",
            "Train Epoch: 1 [5120/10000 (50%)]\tLoss: 0.144907\n",
            "Train Epoch: 1 [7680/10000 (75%)]\tLoss: 0.150698\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.2129, Accuracy: 1476/2000 (74%)\n",
            "\n",
            "Train Epoch: 2 [0/10000 (0%)]\tLoss: 0.163362\n",
            "Train Epoch: 2 [2560/10000 (25%)]\tLoss: 0.158608\n",
            "Train Epoch: 2 [5120/10000 (50%)]\tLoss: 0.161188\n",
            "Train Epoch: 2 [7680/10000 (75%)]\tLoss: 0.184433\n",
            "\n",
            "Test set: Average loss: 1.2114, Accuracy: 1479/2000 (74%)\n",
            "\n",
            "Train Epoch: 3 [0/10000 (0%)]\tLoss: 0.144052\n",
            "Train Epoch: 3 [2560/10000 (25%)]\tLoss: 0.178970\n",
            "Train Epoch: 3 [5120/10000 (50%)]\tLoss: 0.148086\n",
            "Train Epoch: 3 [7680/10000 (75%)]\tLoss: 0.194301\n",
            "\n",
            "Test set: Average loss: 1.2492, Accuracy: 1434/2000 (72%)\n",
            "\n",
            "Train Epoch: 4 [0/10000 (0%)]\tLoss: 0.313484\n",
            "Train Epoch: 4 [2560/10000 (25%)]\tLoss: 0.133979\n",
            "Train Epoch: 4 [5120/10000 (50%)]\tLoss: 0.198121\n",
            "Train Epoch: 4 [7680/10000 (75%)]\tLoss: 0.180826\n",
            "\n",
            "Test set: Average loss: 1.1825, Accuracy: 1465/2000 (73%)\n",
            "\n",
            "Train Epoch: 5 [0/10000 (0%)]\tLoss: 0.213329\n",
            "Train Epoch: 5 [2560/10000 (25%)]\tLoss: 0.118357\n",
            "Train Epoch: 5 [5120/10000 (50%)]\tLoss: 0.294744\n",
            "Train Epoch: 5 [7680/10000 (75%)]\tLoss: 0.209165\n",
            "\n",
            "Test set: Average loss: 1.1411, Accuracy: 1435/2000 (72%)\n",
            "\n",
            "Train Epoch: 6 [0/10000 (0%)]\tLoss: 0.197608\n",
            "Train Epoch: 6 [2560/10000 (25%)]\tLoss: 0.193770\n",
            "Train Epoch: 6 [5120/10000 (50%)]\tLoss: 0.199084\n",
            "Train Epoch: 6 [7680/10000 (75%)]\tLoss: 0.196461\n",
            "\n",
            "Test set: Average loss: 1.1978, Accuracy: 1467/2000 (73%)\n",
            "\n",
            "Train Epoch: 7 [0/10000 (0%)]\tLoss: 0.160710\n",
            "Train Epoch: 7 [2560/10000 (25%)]\tLoss: 0.153850\n",
            "Train Epoch: 7 [5120/10000 (50%)]\tLoss: 0.222371\n",
            "Train Epoch: 7 [7680/10000 (75%)]\tLoss: 0.174390\n",
            "\n",
            "Test set: Average loss: 1.2724, Accuracy: 1482/2000 (74%)\n",
            "\n",
            "Train Epoch: 8 [0/10000 (0%)]\tLoss: 0.175428\n",
            "Train Epoch: 8 [2560/10000 (25%)]\tLoss: 0.179305\n",
            "Train Epoch: 8 [5120/10000 (50%)]\tLoss: 0.163192\n",
            "Train Epoch: 8 [7680/10000 (75%)]\tLoss: 0.179088\n",
            "\n",
            "Test set: Average loss: 1.2325, Accuracy: 1471/2000 (74%)\n",
            "\n",
            "Train Epoch: 9 [0/10000 (0%)]\tLoss: 0.186484\n",
            "Train Epoch: 9 [2560/10000 (25%)]\tLoss: 0.205334\n",
            "Train Epoch: 9 [5120/10000 (50%)]\tLoss: 0.203779\n",
            "Train Epoch: 9 [7680/10000 (75%)]\tLoss: 0.140768\n",
            "\n",
            "Test set: Average loss: 1.2042, Accuracy: 1464/2000 (73%)\n",
            "\n",
            "Train Epoch: 10 [0/10000 (0%)]\tLoss: 0.164376\n",
            "Train Epoch: 10 [2560/10000 (25%)]\tLoss: 0.183796\n",
            "Train Epoch: 10 [5120/10000 (50%)]\tLoss: 0.207435\n",
            "Train Epoch: 10 [7680/10000 (75%)]\tLoss: 0.163384\n",
            "\n",
            "Test set: Average loss: 1.2631, Accuracy: 1443/2000 (72%)\n",
            "\n",
            "Train Epoch: 11 [0/10000 (0%)]\tLoss: 0.276525\n",
            "Train Epoch: 11 [2560/10000 (25%)]\tLoss: 0.207901\n",
            "Train Epoch: 11 [5120/10000 (50%)]\tLoss: 0.243993\n",
            "Train Epoch: 11 [7680/10000 (75%)]\tLoss: 0.180859\n",
            "\n",
            "Test set: Average loss: 1.2103, Accuracy: 1470/2000 (74%)\n",
            "\n",
            "Train Epoch: 12 [0/10000 (0%)]\tLoss: 0.238639\n",
            "Train Epoch: 12 [2560/10000 (25%)]\tLoss: 0.179632\n",
            "Train Epoch: 12 [5120/10000 (50%)]\tLoss: 0.188953\n",
            "Train Epoch: 12 [7680/10000 (75%)]\tLoss: 0.119464\n",
            "\n",
            "Test set: Average loss: 1.2282, Accuracy: 1458/2000 (73%)\n",
            "\n",
            "Train Epoch: 13 [0/10000 (0%)]\tLoss: 0.127019\n",
            "Train Epoch: 13 [2560/10000 (25%)]\tLoss: 0.186781\n",
            "Train Epoch: 13 [5120/10000 (50%)]\tLoss: 0.150175\n",
            "Train Epoch: 13 [7680/10000 (75%)]\tLoss: 0.162692\n",
            "\n",
            "Test set: Average loss: 1.2104, Accuracy: 1468/2000 (73%)\n",
            "\n",
            "Train Epoch: 14 [0/10000 (0%)]\tLoss: 0.236213\n",
            "Train Epoch: 14 [2560/10000 (25%)]\tLoss: 0.215625\n",
            "Train Epoch: 14 [5120/10000 (50%)]\tLoss: 0.198525\n",
            "Train Epoch: 14 [7680/10000 (75%)]\tLoss: 0.180190\n",
            "\n",
            "Test set: Average loss: 1.1986, Accuracy: 1476/2000 (74%)\n",
            "\n",
            "Train Epoch: 15 [0/10000 (0%)]\tLoss: 0.210157\n",
            "Train Epoch: 15 [2560/10000 (25%)]\tLoss: 0.189621\n",
            "Train Epoch: 15 [5120/10000 (50%)]\tLoss: 0.161548\n",
            "Train Epoch: 15 [7680/10000 (75%)]\tLoss: 0.155940\n",
            "\n",
            "Test set: Average loss: 1.2068, Accuracy: 1485/2000 (74%)\n",
            "\n",
            "Train Epoch: 16 [0/10000 (0%)]\tLoss: 0.132099\n",
            "Train Epoch: 16 [2560/10000 (25%)]\tLoss: 0.168032\n",
            "Train Epoch: 16 [5120/10000 (50%)]\tLoss: 0.194588\n",
            "Train Epoch: 16 [7680/10000 (75%)]\tLoss: 0.150964\n",
            "\n",
            "Test set: Average loss: 1.2161, Accuracy: 1470/2000 (74%)\n",
            "\n",
            "Train Epoch: 17 [0/10000 (0%)]\tLoss: 0.179536\n",
            "Train Epoch: 17 [2560/10000 (25%)]\tLoss: 0.140626\n",
            "Train Epoch: 17 [5120/10000 (50%)]\tLoss: 0.166860\n",
            "Train Epoch: 17 [7680/10000 (75%)]\tLoss: 0.173611\n",
            "\n",
            "Test set: Average loss: 1.2407, Accuracy: 1469/2000 (73%)\n",
            "\n",
            "Train Epoch: 18 [0/10000 (0%)]\tLoss: 0.184192\n",
            "Train Epoch: 18 [2560/10000 (25%)]\tLoss: 0.138512\n",
            "Train Epoch: 18 [5120/10000 (50%)]\tLoss: 0.156225\n",
            "Train Epoch: 18 [7680/10000 (75%)]\tLoss: 0.126234\n",
            "\n",
            "Test set: Average loss: 1.2502, Accuracy: 1465/2000 (73%)\n",
            "\n",
            "Train Epoch: 19 [0/10000 (0%)]\tLoss: 0.203624\n",
            "Train Epoch: 19 [2560/10000 (25%)]\tLoss: 0.217756\n",
            "Train Epoch: 19 [5120/10000 (50%)]\tLoss: 0.164120\n",
            "Train Epoch: 19 [7680/10000 (75%)]\tLoss: 0.157363\n",
            "\n",
            "Test set: Average loss: 1.2370, Accuracy: 1482/2000 (74%)\n",
            "\n",
            "Train Epoch: 20 [0/10000 (0%)]\tLoss: 0.154413\n",
            "Train Epoch: 20 [2560/10000 (25%)]\tLoss: 0.138590\n",
            "Train Epoch: 20 [5120/10000 (50%)]\tLoss: 0.123286\n",
            "Train Epoch: 20 [7680/10000 (75%)]\tLoss: 0.164359\n",
            "\n",
            "Test set: Average loss: 1.2175, Accuracy: 1462/2000 (73%)\n",
            "\n",
            "Train Epoch: 21 [0/10000 (0%)]\tLoss: 0.161009\n",
            "Train Epoch: 21 [2560/10000 (25%)]\tLoss: 0.136704\n",
            "Train Epoch: 21 [5120/10000 (50%)]\tLoss: 0.146269\n",
            "Train Epoch: 21 [7680/10000 (75%)]\tLoss: 0.136511\n",
            "\n",
            "Test set: Average loss: 1.2547, Accuracy: 1475/2000 (74%)\n",
            "\n",
            "Train Epoch: 22 [0/10000 (0%)]\tLoss: 0.190467\n",
            "Train Epoch: 22 [2560/10000 (25%)]\tLoss: 0.179386\n",
            "Train Epoch: 22 [5120/10000 (50%)]\tLoss: 0.137953\n",
            "Train Epoch: 22 [7680/10000 (75%)]\tLoss: 0.154203\n",
            "\n",
            "Test set: Average loss: 1.2775, Accuracy: 1466/2000 (73%)\n",
            "\n",
            "Train Epoch: 23 [0/10000 (0%)]\tLoss: 0.179932\n",
            "Train Epoch: 23 [2560/10000 (25%)]\tLoss: 0.156433\n",
            "Train Epoch: 23 [5120/10000 (50%)]\tLoss: 0.147662\n",
            "Train Epoch: 23 [7680/10000 (75%)]\tLoss: 0.163760\n",
            "\n",
            "Test set: Average loss: 1.2733, Accuracy: 1465/2000 (73%)\n",
            "\n",
            "Train Epoch: 24 [0/10000 (0%)]\tLoss: 0.173235\n",
            "Train Epoch: 24 [2560/10000 (25%)]\tLoss: 0.144963\n",
            "Train Epoch: 24 [5120/10000 (50%)]\tLoss: 0.150218\n",
            "Train Epoch: 24 [7680/10000 (75%)]\tLoss: 0.212405\n",
            "\n",
            "Test set: Average loss: 1.2307, Accuracy: 1465/2000 (73%)\n",
            "\n",
            "Train Epoch: 25 [0/10000 (0%)]\tLoss: 0.169645\n",
            "Train Epoch: 25 [2560/10000 (25%)]\tLoss: 0.182699\n",
            "Train Epoch: 25 [5120/10000 (50%)]\tLoss: 0.160418\n",
            "Train Epoch: 25 [7680/10000 (75%)]\tLoss: 0.177850\n",
            "\n",
            "Test set: Average loss: 1.2102, Accuracy: 1464/2000 (73%)\n",
            "\n",
            "Train Epoch: 26 [0/10000 (0%)]\tLoss: 0.180994\n",
            "Train Epoch: 26 [2560/10000 (25%)]\tLoss: 0.250231\n",
            "Train Epoch: 26 [5120/10000 (50%)]\tLoss: 0.188329\n",
            "Train Epoch: 26 [7680/10000 (75%)]\tLoss: 0.201771\n",
            "\n",
            "Test set: Average loss: 1.2131, Accuracy: 1474/2000 (74%)\n",
            "\n",
            "Train Epoch: 27 [0/10000 (0%)]\tLoss: 0.148853\n",
            "Train Epoch: 27 [2560/10000 (25%)]\tLoss: 0.136822\n",
            "Train Epoch: 27 [5120/10000 (50%)]\tLoss: 0.171248\n",
            "Train Epoch: 27 [7680/10000 (75%)]\tLoss: 0.143732\n",
            "\n",
            "Test set: Average loss: 1.2568, Accuracy: 1425/2000 (71%)\n",
            "\n",
            "Train Epoch: 28 [0/10000 (0%)]\tLoss: 0.219904\n",
            "Train Epoch: 28 [2560/10000 (25%)]\tLoss: 0.170903\n",
            "Train Epoch: 28 [5120/10000 (50%)]\tLoss: 0.190099\n",
            "Train Epoch: 28 [7680/10000 (75%)]\tLoss: 0.183093\n",
            "\n",
            "Test set: Average loss: 1.2398, Accuracy: 1466/2000 (73%)\n",
            "\n",
            "Train Epoch: 29 [0/10000 (0%)]\tLoss: 0.165147\n",
            "Train Epoch: 29 [2560/10000 (25%)]\tLoss: 0.202043\n",
            "Train Epoch: 29 [5120/10000 (50%)]\tLoss: 0.181682\n",
            "Train Epoch: 29 [7680/10000 (75%)]\tLoss: 0.219124\n",
            "\n",
            "Test set: Average loss: 1.2411, Accuracy: 1469/2000 (73%)\n",
            "\n",
            "Train Epoch: 30 [0/10000 (0%)]\tLoss: 0.211686\n",
            "Train Epoch: 30 [2560/10000 (25%)]\tLoss: 0.149886\n",
            "Train Epoch: 30 [5120/10000 (50%)]\tLoss: 0.161670\n",
            "Train Epoch: 30 [7680/10000 (75%)]\tLoss: 0.155941\n",
            "\n",
            "Test set: Average loss: 1.2421, Accuracy: 1478/2000 (74%)\n",
            "\n",
            "Train Epoch: 31 [0/10000 (0%)]\tLoss: 0.139038\n",
            "Train Epoch: 31 [2560/10000 (25%)]\tLoss: 0.141580\n",
            "Train Epoch: 31 [5120/10000 (50%)]\tLoss: 0.121481\n",
            "Train Epoch: 31 [7680/10000 (75%)]\tLoss: 0.141521\n",
            "\n",
            "Test set: Average loss: 1.2873, Accuracy: 1461/2000 (73%)\n",
            "\n",
            "Train Epoch: 32 [0/10000 (0%)]\tLoss: 0.209931\n",
            "Train Epoch: 32 [2560/10000 (25%)]\tLoss: 0.188500\n",
            "Train Epoch: 32 [5120/10000 (50%)]\tLoss: 0.148297\n",
            "Train Epoch: 32 [7680/10000 (75%)]\tLoss: 0.181207\n",
            "\n",
            "Test set: Average loss: 1.2874, Accuracy: 1489/2000 (74%)\n",
            "\n",
            "Train Epoch: 33 [0/10000 (0%)]\tLoss: 0.181029\n",
            "Train Epoch: 33 [2560/10000 (25%)]\tLoss: 0.168547\n",
            "Train Epoch: 33 [5120/10000 (50%)]\tLoss: 0.153888\n",
            "Train Epoch: 33 [7680/10000 (75%)]\tLoss: 0.142100\n",
            "\n",
            "Test set: Average loss: 1.3112, Accuracy: 1473/2000 (74%)\n",
            "\n",
            "Train Epoch: 34 [0/10000 (0%)]\tLoss: 0.188816\n",
            "Train Epoch: 34 [2560/10000 (25%)]\tLoss: 0.154412\n",
            "Train Epoch: 34 [5120/10000 (50%)]\tLoss: 0.179777\n",
            "Train Epoch: 34 [7680/10000 (75%)]\tLoss: 0.172080\n",
            "\n",
            "Test set: Average loss: 1.2765, Accuracy: 1479/2000 (74%)\n",
            "\n",
            "Train Epoch: 35 [0/10000 (0%)]\tLoss: 0.172574\n",
            "Train Epoch: 35 [2560/10000 (25%)]\tLoss: 0.149831\n",
            "Train Epoch: 35 [5120/10000 (50%)]\tLoss: 0.144337\n",
            "Train Epoch: 35 [7680/10000 (75%)]\tLoss: 0.134049\n",
            "\n",
            "Test set: Average loss: 1.3597, Accuracy: 1473/2000 (74%)\n",
            "\n",
            "Train Epoch: 36 [0/10000 (0%)]\tLoss: 0.198159\n",
            "Train Epoch: 36 [2560/10000 (25%)]\tLoss: 0.150299\n",
            "Train Epoch: 36 [5120/10000 (50%)]\tLoss: 0.170928\n",
            "Train Epoch: 36 [7680/10000 (75%)]\tLoss: 0.123754\n",
            "\n",
            "Test set: Average loss: 1.2328, Accuracy: 1458/2000 (73%)\n",
            "\n",
            "Train Epoch: 37 [0/10000 (0%)]\tLoss: 0.184588\n",
            "Train Epoch: 37 [2560/10000 (25%)]\tLoss: 0.157862\n",
            "Train Epoch: 37 [5120/10000 (50%)]\tLoss: 0.118349\n",
            "Train Epoch: 37 [7680/10000 (75%)]\tLoss: 0.185542\n",
            "\n",
            "Test set: Average loss: 1.2436, Accuracy: 1464/2000 (73%)\n",
            "\n",
            "Train Epoch: 38 [0/10000 (0%)]\tLoss: 0.167341\n",
            "Train Epoch: 38 [2560/10000 (25%)]\tLoss: 0.120936\n",
            "Train Epoch: 38 [5120/10000 (50%)]\tLoss: 0.168795\n",
            "Train Epoch: 38 [7680/10000 (75%)]\tLoss: 0.173312\n",
            "\n",
            "Test set: Average loss: 1.2793, Accuracy: 1472/2000 (74%)\n",
            "\n",
            "Train Epoch: 39 [0/10000 (0%)]\tLoss: 0.172326\n",
            "Train Epoch: 39 [2560/10000 (25%)]\tLoss: 0.130769\n",
            "Train Epoch: 39 [5120/10000 (50%)]\tLoss: 0.133477\n",
            "Train Epoch: 39 [7680/10000 (75%)]\tLoss: 0.171041\n",
            "\n",
            "Test set: Average loss: 1.2549, Accuracy: 1480/2000 (74%)\n",
            "\n",
            "Train Epoch: 40 [0/10000 (0%)]\tLoss: 0.167126\n",
            "Train Epoch: 40 [2560/10000 (25%)]\tLoss: 0.132499\n",
            "Train Epoch: 40 [5120/10000 (50%)]\tLoss: 0.130984\n",
            "Train Epoch: 40 [7680/10000 (75%)]\tLoss: 0.113988\n",
            "\n",
            "Test set: Average loss: 1.3060, Accuracy: 1474/2000 (74%)\n",
            "\n",
            "Train Epoch: 41 [0/10000 (0%)]\tLoss: 0.199328\n",
            "Train Epoch: 41 [2560/10000 (25%)]\tLoss: 0.117060\n",
            "Train Epoch: 41 [5120/10000 (50%)]\tLoss: 0.121902\n",
            "Train Epoch: 41 [7680/10000 (75%)]\tLoss: 0.106503\n",
            "\n",
            "Test set: Average loss: 1.3090, Accuracy: 1479/2000 (74%)\n",
            "\n",
            "Train Epoch: 42 [0/10000 (0%)]\tLoss: 0.245800\n",
            "Train Epoch: 42 [2560/10000 (25%)]\tLoss: 0.125913\n",
            "Train Epoch: 42 [5120/10000 (50%)]\tLoss: 0.183414\n",
            "Train Epoch: 42 [7680/10000 (75%)]\tLoss: 0.212111\n",
            "\n",
            "Test set: Average loss: 1.2893, Accuracy: 1469/2000 (73%)\n",
            "\n",
            "Train Epoch: 43 [0/10000 (0%)]\tLoss: 0.165606\n",
            "Train Epoch: 43 [2560/10000 (25%)]\tLoss: 0.162562\n",
            "Train Epoch: 43 [5120/10000 (50%)]\tLoss: 0.193817\n",
            "Train Epoch: 43 [7680/10000 (75%)]\tLoss: 0.160808\n",
            "\n",
            "Test set: Average loss: 1.3099, Accuracy: 1476/2000 (74%)\n",
            "\n",
            "Train Epoch: 44 [0/10000 (0%)]\tLoss: 0.154653\n",
            "Train Epoch: 44 [2560/10000 (25%)]\tLoss: 0.166482\n",
            "Train Epoch: 44 [5120/10000 (50%)]\tLoss: 0.180901\n",
            "Train Epoch: 44 [7680/10000 (75%)]\tLoss: 0.128359\n",
            "\n",
            "Test set: Average loss: 1.3103, Accuracy: 1461/2000 (73%)\n",
            "\n",
            "Train Epoch: 45 [0/10000 (0%)]\tLoss: 0.164148\n",
            "Train Epoch: 45 [2560/10000 (25%)]\tLoss: 0.124706\n",
            "Train Epoch: 45 [5120/10000 (50%)]\tLoss: 0.103683\n",
            "Train Epoch: 45 [7680/10000 (75%)]\tLoss: 0.128654\n",
            "\n",
            "Test set: Average loss: 1.3624, Accuracy: 1441/2000 (72%)\n",
            "\n",
            "Train Epoch: 46 [0/10000 (0%)]\tLoss: 0.182775\n",
            "Train Epoch: 46 [2560/10000 (25%)]\tLoss: 0.182219\n",
            "Train Epoch: 46 [5120/10000 (50%)]\tLoss: 0.156128\n",
            "Train Epoch: 46 [7680/10000 (75%)]\tLoss: 0.207957\n",
            "\n",
            "Test set: Average loss: 1.3010, Accuracy: 1483/2000 (74%)\n",
            "\n",
            "Train Epoch: 47 [0/10000 (0%)]\tLoss: 0.145966\n",
            "Train Epoch: 47 [2560/10000 (25%)]\tLoss: 0.148050\n",
            "Train Epoch: 47 [5120/10000 (50%)]\tLoss: 0.157453\n",
            "Train Epoch: 47 [7680/10000 (75%)]\tLoss: 0.145518\n",
            "\n",
            "Test set: Average loss: 1.3425, Accuracy: 1452/2000 (73%)\n",
            "\n",
            "Train Epoch: 48 [0/10000 (0%)]\tLoss: 0.159337\n",
            "Train Epoch: 48 [2560/10000 (25%)]\tLoss: 0.165860\n",
            "Train Epoch: 48 [5120/10000 (50%)]\tLoss: 0.133843\n",
            "Train Epoch: 48 [7680/10000 (75%)]\tLoss: 0.147589\n",
            "\n",
            "Test set: Average loss: 1.3272, Accuracy: 1463/2000 (73%)\n",
            "\n",
            "Train Epoch: 49 [0/10000 (0%)]\tLoss: 0.132320\n",
            "Train Epoch: 49 [2560/10000 (25%)]\tLoss: 0.145484\n",
            "Train Epoch: 49 [5120/10000 (50%)]\tLoss: 0.146917\n",
            "Train Epoch: 49 [7680/10000 (75%)]\tLoss: 0.155663\n",
            "\n",
            "Test set: Average loss: 1.3586, Accuracy: 1472/2000 (74%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vu_UfCuTOstZ",
        "colab_type": "code",
        "outputId": "26333189-512c-48e9-a7d9-4c3db14642d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "plt.plot(tests)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Model Accuracy Over Time')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8b65e8befe62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy Over Time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nvU4nTFQxH5",
        "colab_type": "code",
        "outputId": "6ff2a907-f936-4845-cf70-5cd71433d88d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}